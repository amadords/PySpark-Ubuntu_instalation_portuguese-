{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Download](https://spark.apache.org/downloads.html) na página oficial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Os códigos a seguir devem ser executados preferencialmente via terminal\n",
    "* Os sinais de exclamação (!) são apenas para uso de comandos para o Sistema Operacional, via notebook. se for executar no terminal, retire-os.\n",
    "* Atenção para a versão que você irá baixar, aqui estou utilizando a 3.0.0, então altere se você estiver com outra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# antes de tudo instale as dependências com cada linha a seguir\n",
    "# java8\n",
    "sudo apt update\n",
    "sudo apt install openjdk-8-jdk openjdk-8-jre\n",
    "#verificando a versão do java\n",
    "java - version\n",
    "# configurando as variáveis JAVA_HOME e JRE-HOME\n",
    "cat >> /etc/environment <<EOL\n",
    "JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n",
    "JRE_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre\n",
    "# saindo do EOL\n",
    "EOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original por [MGalarnyk](https://github.com/mGalarnyk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrindo o diretório de downloads\n",
    "cd Downloads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movendo os arquivos para o /home\n",
    "mv spark-3.0.0-bin-hadoop2.7.tgz ~/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrindo diretório home\n",
    "cd ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instalação\n",
    "tar -zxvf spark-3.0.0-bin-hadoop2.7.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletando o arquivo baixado\n",
    "rm spark-3.0.0-bin-hadoop2.7.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use o seguinte comando para verificar se você possui um arquivo .bashrc\n",
    "ls -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Em seguida, editaremos nosso arquivo .bashrc para que possamos abrir um bloco de anotações em qualquer diretório\n",
    "# nano é um editor de texto\n",
    "nano .bashrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Não apagar nada no .bashrc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adicionar o seguinte código no nano, ao final\n",
    "\n",
    "function snotebook ()\n",
    "{\n",
    "\n",
    "#Spark path (based on your computer)\n",
    "SPARK_PATH=~/spark-3.0.0-bin-hadoop2.7\n",
    "\n",
    "export PYSPARK_DRIVER_PYTHON=\"jupyter\"\n",
    "export PYSPARK_DRIVER_PYTHON_OPTS=\"notebook\"\n",
    "\n",
    "$SPARK_PATH/bin/pyspark --master local[2]\n",
    "\n",
    "}\n",
    "\n",
    "# aperte 'ctrl+x' para sair do nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando e saindo do arquivo .bashrc\n",
    "# após isso, feche e abra um novo terminal\n",
    "source .bashrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retornando ao desktop\n",
    "cd Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ainda no terminal\n",
    "# caso não tenha o git instalado: sudo apt install git\n",
    "# após isso rodar o código abaixo\n",
    "git clone https://github.com/mGalarnyk/Installations_Mac_Ubuntu_Windows.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrir o diretório onde estão os arquivos\n",
    "cd Installations_Mac_Ubuntu_Windows/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roda o seguinte comando no terminal\n",
    "snotebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removendo diretório com arquivos dentro\n",
    "rm -rf Installations_Mac_Ubuntu_Windows/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instalação do pyspark\n",
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importação para teste\n",
    "from pyspark.sql import SparkSession"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
